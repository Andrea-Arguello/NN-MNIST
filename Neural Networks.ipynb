{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Universidad del Valle de Guatemala\n",
    "<br>\n",
    "Inteligencia Artificial\n",
    "<br>\n",
    "Andrea Argüello 17801\n",
    "<br>\n",
    "<center><b><font size=\"6\">Laboratorio 2: Redes Neuronales</font></b></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Modelo\n",
    "## 1.1 Modelo #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import neural_networks as nn\n",
    "from scipy.optimize import minimize\n",
    "from collections import Counter, OrderedDict, defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv(r'./datasets/csv/fashion-mnist_train.csv')\n",
    "test = pd.read_csv(r'./datasets/csv/fashion-mnist_test.csv')\n",
    "\n",
    "#shuffled = df.sample(frac=1)\n",
    "\n",
    "#train, validate = np.split(shuffled, [50000])\n",
    "#train.to_csv(path_or_buf='./datasets/csv/fashion-mnist_train_50k.csv',index=False)\n",
    "#validate.to_csv(path_or_buf='./fashion-mnist_validate.csv',index=False)\n",
    "\n",
    "train = pd.read_csv(r'./datasets/csv/fashion-mnist_train_50k.csv')\n",
    "validate = pd.read_csv(r'./datasets/csv/fashion-mnist_validate.csv')\n",
    "\n",
    "NORMALIZE = 1000.0\n",
    "train_X = train[train.columns[~train.columns.isin(['label'])]].to_numpy() / NORMALIZE\n",
    "train_y = train[['label']].to_numpy()\n",
    "validate_X = validate[validate.columns[~validate.columns.isin(['label'])]].to_numpy() / NORMALIZE\n",
    "validate_y = validate[['label']].to_numpy()\n",
    "test_X = test[test.columns[~test.columns.isin(['label'])]].to_numpy() / NORMALIZE\n",
    "test_y = test[['label']].to_numpy()\n",
    "\n",
    "train_Y = (train_y == np.asarray(range(10))).astype(int)\n",
    "validate_Y = (validate_y == np.asarray(range(10))).astype(int)\n",
    "test_Y = (test_y == np.asarray(range(10))).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A setear variables\n",
    "NETWORK_ARCH = np.array([\n",
    "    784,\n",
    "    90, # ~(784*10)**0.5\n",
    "    10\n",
    "    ])\n",
    "theta_shapes = np.hstack((\n",
    "    NETWORK_ARCH[1:].reshape(len(NETWORK_ARCH)-1,1),\n",
    "    (NETWORK_ARCH[:-1]+1).reshape(len(NETWORK_ARCH)-1,1)\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Otras variables\n",
    "#flat_thetas = nn.flatten_list_of_arrays([\n",
    "#    np.random.rand(*theta_shape) for theta_shape in theta_shapes\n",
    "#])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_thetas = np.load('flat_thetas3.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.1 Optimización con scipy.optimize.minimize\n",
    "Esto se realizó en el archivo jupyter.py por aparte, ya que en jupyter se quedó en caché un error que persistió sin importar cuantas veces reiniciase el kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = np.load('result.npy') #este es result.x\n",
    "#result = result.reshape(len(result),1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2 Accuracy con el train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_thetas = nn.inflate_matrices(result, theta_shapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_a_train = nn.feed_forward(new_thetas, train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se obtienen los indices del porcentaje mas alto\n",
    "def accuracy(predictions, y):\n",
    "    pred = np.argmax(predictions[-1], axis = 1).reshape(len(predictions[-1]),1)\n",
    "    correct = ((pred==y) * 1).sum()\n",
    "        \n",
    "    print(\"Success: \", correct, \" out of \", len(predictions[-1]), \", i.e. \", correct * 100/len(predictions[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success:  44172  out of  50000 , i.e.  88.344\n"
     ]
    }
   ],
   "source": [
    "accuracy(new_a_train, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.3 Accuracy del cross validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success:  8503  out of  10000 , i.e.  85.03\n"
     ]
    }
   ],
   "source": [
    "new_a_validate = nn.feed_forward(new_thetas, validate_X)\n",
    "accuracy(new_a_validate, validate_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.4 Análisis previo a Test set\n",
    "Veamos cuáles son las imágenes que más le cuesta identificar...\n",
    "\n",
    "#### 1.1.4.1 Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"T-shirt/top\", \"Trouser\",\"Pullover\",\"Dress\",\"Coat\",\"Sandal\",\"Shirt\",\"Sneaker\",\"Bag\",\"Ankle boot\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freq_table(predictions, y):\n",
    "    assignation = []\n",
    "    pred = np.argmax(predictions[-1], axis = 1).reshape(len(predictions[-1]),1).tolist()\n",
    "    y=y.tolist()\n",
    "    for i in range(len(pred)):\n",
    "        assignation.append(tuple([labels[y[i][0]], labels[pred[i][0]]]))\n",
    "    return Counter(map(tuple,tuple(assignation)))\n",
    "\n",
    "def totals_table(assignation_freq_table):\n",
    "    mapping = defaultdict(list) #You do not need a defaultdict per se, i just find them more graceful when you do not have a certain key.\n",
    "    for k in OrderedDict(sorted(assignation_freq_table.items())):\n",
    "        mapping[k[0]].append(k)\n",
    "    totals = defaultdict(list)\n",
    "    for k in mapping:\n",
    "        all_k = 0\n",
    "        for v in mapping[k]:\n",
    "            all_k+=assignation_freq_table[v]\n",
    "        totals[k].append(all_k)\n",
    "    return totals\n",
    "\n",
    "def freq_and_totals(predictions,y):\n",
    "    return freq_table(predictions,y), totals_table(freq_table(predictions,y)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "assignation_freq, totals = freq_and_totals(new_a_train,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected  Ankle boot , got Ankle boot :  4896 out of 5040 i.e. 97.14 %\n",
      "Expected  Ankle boot , got Bag :  2 out of 5040 i.e. 0.04 %\n",
      "Expected  Ankle boot , got Sandal :  26 out of 5040 i.e. 0.52 %\n",
      "Expected  Ankle boot , got Sneaker :  116 out of 5040 i.e. 2.3 %\n",
      "Expected  Bag , got Ankle boot :  3 out of 4983 i.e. 0.06 %\n",
      "Expected  Bag , got Bag :  4847 out of 4983 i.e. 97.27 %\n",
      "Expected  Bag , got Coat :  16 out of 4983 i.e. 0.32 %\n",
      "Expected  Bag , got Dress :  16 out of 4983 i.e. 0.32 %\n",
      "Expected  Bag , got Pullover :  18 out of 4983 i.e. 0.36 %\n",
      "Expected  Bag , got Sandal :  2 out of 4983 i.e. 0.04 %\n",
      "Expected  Bag , got Shirt :  53 out of 4983 i.e. 1.06 %\n",
      "Expected  Bag , got Sneaker :  4 out of 4983 i.e. 0.08 %\n",
      "Expected  Bag , got T-shirt/top :  22 out of 4983 i.e. 0.44 %\n",
      "Expected  Bag , got Trouser :  2 out of 4983 i.e. 0.04 %\n",
      "Expected  Coat , got Bag :  1 out of 4972 i.e. 0.02 %\n",
      "Expected  Coat , got Coat :  4016 out of 4972 i.e. 80.77 %\n",
      "Expected  Coat , got Dress :  140 out of 4972 i.e. 2.82 %\n",
      "Expected  Coat , got Pullover :  443 out of 4972 i.e. 8.91 %\n",
      "Expected  Coat , got Shirt :  345 out of 4972 i.e. 6.94 %\n",
      "Expected  Coat , got T-shirt/top :  17 out of 4972 i.e. 0.34 %\n",
      "Expected  Coat , got Trouser :  10 out of 4972 i.e. 0.2 %\n",
      "Expected  Dress , got Bag :  5 out of 4999 i.e. 0.1 %\n",
      "Expected  Dress , got Coat :  163 out of 4999 i.e. 3.26 %\n",
      "Expected  Dress , got Dress :  4372 out of 4999 i.e. 87.46 %\n",
      "Expected  Dress , got Pullover :  64 out of 4999 i.e. 1.28 %\n",
      "Expected  Dress , got Shirt :  183 out of 4999 i.e. 3.66 %\n",
      "Expected  Dress , got T-shirt/top :  170 out of 4999 i.e. 3.4 %\n",
      "Expected  Dress , got Trouser :  42 out of 4999 i.e. 0.84 %\n",
      "Expected  Pullover , got Bag :  6 out of 4995 i.e. 0.12 %\n",
      "Expected  Pullover , got Coat :  550 out of 4995 i.e. 11.01 %\n",
      "Expected  Pullover , got Dress :  43 out of 4995 i.e. 0.86 %\n",
      "Expected  Pullover , got Pullover :  3974 out of 4995 i.e. 79.56 %\n",
      "Expected  Pullover , got Shirt :  342 out of 4995 i.e. 6.85 %\n",
      "Expected  Pullover , got T-shirt/top :  70 out of 4995 i.e. 1.4 %\n",
      "Expected  Pullover , got Trouser :  10 out of 4995 i.e. 0.2 %\n",
      "Expected  Sandal , got Ankle boot :  27 out of 5015 i.e. 0.54 %\n",
      "Expected  Sandal , got Pullover :  1 out of 5015 i.e. 0.02 %\n",
      "Expected  Sandal , got Sandal :  4940 out of 5015 i.e. 98.5 %\n",
      "Expected  Sandal , got Sneaker :  47 out of 5015 i.e. 0.94 %\n",
      "Expected  Shirt , got Bag :  23 out of 5010 i.e. 0.46 %\n",
      "Expected  Shirt , got Coat :  444 out of 5010 i.e. 8.86 %\n",
      "Expected  Shirt , got Dress :  146 out of 5010 i.e. 2.91 %\n",
      "Expected  Shirt , got Pullover :  541 out of 5010 i.e. 10.8 %\n",
      "Expected  Shirt , got Sandal :  1 out of 5010 i.e. 0.02 %\n",
      "Expected  Shirt , got Shirt :  3151 out of 5010 i.e. 62.89 %\n",
      "Expected  Shirt , got T-shirt/top :  696 out of 5010 i.e. 13.89 %\n",
      "Expected  Shirt , got Trouser :  8 out of 5010 i.e. 0.16 %\n",
      "Expected  Sneaker , got Ankle boot :  124 out of 5006 i.e. 2.48 %\n",
      "Expected  Sneaker , got Bag :  4 out of 5006 i.e. 0.08 %\n",
      "Expected  Sneaker , got Sandal :  23 out of 5006 i.e. 0.46 %\n",
      "Expected  Sneaker , got Sneaker :  4855 out of 5006 i.e. 96.98 %\n",
      "Expected  T-shirt/top , got Bag :  24 out of 4996 i.e. 0.48 %\n",
      "Expected  T-shirt/top , got Coat :  22 out of 4996 i.e. 0.44 %\n",
      "Expected  T-shirt/top , got Dress :  183 out of 4996 i.e. 3.66 %\n",
      "Expected  T-shirt/top , got Pullover :  61 out of 4996 i.e. 1.22 %\n",
      "Expected  T-shirt/top , got Sandal :  1 out of 4996 i.e. 0.02 %\n",
      "Expected  T-shirt/top , got Shirt :  374 out of 4996 i.e. 7.49 %\n",
      "Expected  T-shirt/top , got Sneaker :  1 out of 4996 i.e. 0.02 %\n",
      "Expected  T-shirt/top , got T-shirt/top :  4310 out of 4996 i.e. 86.27 %\n",
      "Expected  T-shirt/top , got Trouser :  20 out of 4996 i.e. 0.4 %\n",
      "Expected  Trouser , got Bag :  1 out of 4984 i.e. 0.02 %\n",
      "Expected  Trouser , got Coat :  33 out of 4984 i.e. 0.66 %\n",
      "Expected  Trouser , got Dress :  87 out of 4984 i.e. 1.75 %\n",
      "Expected  Trouser , got Pullover :  21 out of 4984 i.e. 0.42 %\n",
      "Expected  Trouser , got Shirt :  2 out of 4984 i.e. 0.04 %\n",
      "Expected  Trouser , got T-shirt/top :  29 out of 4984 i.e. 0.58 %\n",
      "Expected  Trouser , got Trouser :  4811 out of 4984 i.e. 96.53 %\n"
     ]
    }
   ],
   "source": [
    "for k,v in OrderedDict(sorted(assignation_freq.items())):\n",
    "    print(\"Expected \",k,\", got\", v, \": \", assignation_freq[k,v], \"out of\", totals[k][0], \"i.e.\", round(assignation_freq[k,v]*100/totals[k][0],2),\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Esta es mucha información, así que, descartemos los casos que sean muy bajos, i.e., menores al 5%, solo para tener una mejor idea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected  Ankle boot , got Ankle boot :  4896 out of 5040 i.e. 97.14 %\n",
      "Expected  Bag , got Bag :  4847 out of 4983 i.e. 97.27 %\n",
      "Expected  Coat , got Coat :  4016 out of 4972 i.e. 80.77 %\n",
      "Expected  Coat , got Pullover :  443 out of 4972 i.e. 8.91 %\n",
      "Expected  Coat , got Shirt :  345 out of 4972 i.e. 6.94 %\n",
      "Expected  Dress , got Dress :  4372 out of 4999 i.e. 87.46 %\n",
      "Expected  Pullover , got Coat :  550 out of 4995 i.e. 11.01 %\n",
      "Expected  Pullover , got Pullover :  3974 out of 4995 i.e. 79.56 %\n",
      "Expected  Pullover , got Shirt :  342 out of 4995 i.e. 6.85 %\n",
      "Expected  Sandal , got Sandal :  4940 out of 5015 i.e. 98.5 %\n",
      "Expected  Shirt , got Coat :  444 out of 5010 i.e. 8.86 %\n",
      "Expected  Shirt , got Pullover :  541 out of 5010 i.e. 10.8 %\n",
      "Expected  Shirt , got Shirt :  3151 out of 5010 i.e. 62.89 %\n",
      "Expected  Shirt , got T-shirt/top :  696 out of 5010 i.e. 13.89 %\n",
      "Expected  Sneaker , got Sneaker :  4855 out of 5006 i.e. 96.98 %\n",
      "Expected  T-shirt/top , got Shirt :  374 out of 4996 i.e. 7.49 %\n",
      "Expected  T-shirt/top , got T-shirt/top :  4310 out of 4996 i.e. 86.27 %\n",
      "Expected  Trouser , got Trouser :  4811 out of 4984 i.e. 96.53 %\n"
     ]
    }
   ],
   "source": [
    "for k,v in OrderedDict(sorted(assignation_freq.items())):\n",
    "    if(round(assignation_freq[k,v]*100/totals[k][0],2)>=5):\n",
    "        print(\"Expected \",k,\", got\", v, \": \", assignation_freq[k,v], \"out of\", totals[k][0], \"i.e.\", round(assignation_freq[k,v]*100/totals[k][0],2),\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> NOTA: </b> \n",
    "    <ul> \n",
    "        <li> Se puede observar que en el training set, el accuracy más bajo es el de las \"Shirts\", siendo la clasificación de estas correcto el 62.89% de los casos. Se confunde usualmente con \"T-shirt/top\" y \"Pullover\" el 13.89% y 10.8%, respectivamente. También suele confundirse con \"Coat,\" pero esto ocurre en un 8.86% de los casos.\n",
    "        <li> Le sigue \"Pullover\", con 79.56% de asignaciones correctas. Se clasifica erróneamente como \"Coat\" un 11.01% de las veces, y con \"Shirt\" en un 6.94%.\n",
    "        <li> Coat es el tercero más bajo, con 80.77%. También suele confundirse con \"Pullover\" y \"Shirt\".\n",
    "        <li> Cabe destacar además que ninguno de los elementos tuvo un accuracy del 100%. El más alto due el de \"Sandal\" con 98.5% de accuracy. \n",
    "        <li> Si bien \"Bag\" con 97.27% de accuracy es el segundo más alto, este también se asignó incorrectamente a una gran cantidad de elementos, sin ningún parecido en común. Esto podría deberse a la resolución de la imagen.\n",
    "    </ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.4.2 Cross validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected  Ankle boot , got Ankle boot :  907 out of 960 i.e. 94.48 %\n",
      "Expected  Ankle boot , got Bag :  1 out of 960 i.e. 0.1 %\n",
      "Expected  Ankle boot , got Pullover :  1 out of 960 i.e. 0.1 %\n",
      "Expected  Ankle boot , got Sandal :  18 out of 960 i.e. 1.88 %\n",
      "Expected  Ankle boot , got Sneaker :  33 out of 960 i.e. 3.44 %\n",
      "Expected  Bag , got Bag :  949 out of 1017 i.e. 93.31 %\n",
      "Expected  Bag , got Coat :  5 out of 1017 i.e. 0.49 %\n",
      "Expected  Bag , got Dress :  5 out of 1017 i.e. 0.49 %\n",
      "Expected  Bag , got Pullover :  12 out of 1017 i.e. 1.18 %\n",
      "Expected  Bag , got Sandal :  2 out of 1017 i.e. 0.2 %\n",
      "Expected  Bag , got Shirt :  26 out of 1017 i.e. 2.56 %\n",
      "Expected  Bag , got Sneaker :  9 out of 1017 i.e. 0.88 %\n",
      "Expected  Bag , got T-shirt/top :  8 out of 1017 i.e. 0.79 %\n",
      "Expected  Bag , got Trouser :  1 out of 1017 i.e. 0.1 %\n",
      "Expected  Coat , got Bag :  5 out of 1028 i.e. 0.49 %\n",
      "Expected  Coat , got Coat :  814 out of 1028 i.e. 79.18 %\n",
      "Expected  Coat , got Dress :  34 out of 1028 i.e. 3.31 %\n",
      "Expected  Coat , got Pullover :  87 out of 1028 i.e. 8.46 %\n",
      "Expected  Coat , got Shirt :  81 out of 1028 i.e. 7.88 %\n",
      "Expected  Coat , got T-shirt/top :  3 out of 1028 i.e. 0.29 %\n",
      "Expected  Coat , got Trouser :  4 out of 1028 i.e. 0.39 %\n",
      "Expected  Dress , got Bag :  3 out of 1001 i.e. 0.3 %\n",
      "Expected  Dress , got Coat :  36 out of 1001 i.e. 3.6 %\n",
      "Expected  Dress , got Dress :  869 out of 1001 i.e. 86.81 %\n",
      "Expected  Dress , got Pullover :  13 out of 1001 i.e. 1.3 %\n",
      "Expected  Dress , got Shirt :  32 out of 1001 i.e. 3.2 %\n",
      "Expected  Dress , got T-shirt/top :  31 out of 1001 i.e. 3.1 %\n",
      "Expected  Dress , got Trouser :  17 out of 1001 i.e. 1.7 %\n",
      "Expected  Pullover , got Bag :  2 out of 1005 i.e. 0.2 %\n",
      "Expected  Pullover , got Coat :  135 out of 1005 i.e. 13.43 %\n",
      "Expected  Pullover , got Dress :  7 out of 1005 i.e. 0.7 %\n",
      "Expected  Pullover , got Pullover :  749 out of 1005 i.e. 74.53 %\n",
      "Expected  Pullover , got Shirt :  89 out of 1005 i.e. 8.86 %\n",
      "Expected  Pullover , got T-shirt/top :  23 out of 1005 i.e. 2.29 %\n",
      "Expected  Sandal , got Ankle boot :  27 out of 985 i.e. 2.74 %\n",
      "Expected  Sandal , got Bag :  9 out of 985 i.e. 0.91 %\n",
      "Expected  Sandal , got Dress :  1 out of 985 i.e. 0.1 %\n",
      "Expected  Sandal , got Pullover :  1 out of 985 i.e. 0.1 %\n",
      "Expected  Sandal , got Sandal :  916 out of 985 i.e. 92.99 %\n",
      "Expected  Sandal , got Sneaker :  31 out of 985 i.e. 3.15 %\n",
      "Expected  Shirt , got Bag :  14 out of 990 i.e. 1.41 %\n",
      "Expected  Shirt , got Coat :  103 out of 990 i.e. 10.4 %\n",
      "Expected  Shirt , got Dress :  23 out of 990 i.e. 2.32 %\n",
      "Expected  Shirt , got Pullover :  119 out of 990 i.e. 12.02 %\n",
      "Expected  Shirt , got Shirt :  570 out of 990 i.e. 57.58 %\n",
      "Expected  Shirt , got T-shirt/top :  157 out of 990 i.e. 15.86 %\n",
      "Expected  Shirt , got Trouser :  4 out of 990 i.e. 0.4 %\n",
      "Expected  Sneaker , got Ankle boot :  37 out of 994 i.e. 3.72 %\n",
      "Expected  Sneaker , got Sandal :  27 out of 994 i.e. 2.72 %\n",
      "Expected  Sneaker , got Sneaker :  930 out of 994 i.e. 93.56 %\n",
      "Expected  T-shirt/top , got Bag :  10 out of 1004 i.e. 1.0 %\n",
      "Expected  T-shirt/top , got Coat :  9 out of 1004 i.e. 0.9 %\n",
      "Expected  T-shirt/top , got Dress :  45 out of 1004 i.e. 4.48 %\n",
      "Expected  T-shirt/top , got Pullover :  17 out of 1004 i.e. 1.69 %\n",
      "Expected  T-shirt/top , got Sandal :  2 out of 1004 i.e. 0.2 %\n",
      "Expected  T-shirt/top , got Shirt :  87 out of 1004 i.e. 8.67 %\n",
      "Expected  T-shirt/top , got T-shirt/top :  830 out of 1004 i.e. 82.67 %\n",
      "Expected  T-shirt/top , got Trouser :  4 out of 1004 i.e. 0.4 %\n",
      "Expected  Trouser , got Ankle boot :  1 out of 1016 i.e. 0.1 %\n",
      "Expected  Trouser , got Coat :  5 out of 1016 i.e. 0.49 %\n",
      "Expected  Trouser , got Dress :  27 out of 1016 i.e. 2.66 %\n",
      "Expected  Trouser , got Pullover :  3 out of 1016 i.e. 0.3 %\n",
      "Expected  Trouser , got Sandal :  1 out of 1016 i.e. 0.1 %\n",
      "Expected  Trouser , got Shirt :  2 out of 1016 i.e. 0.2 %\n",
      "Expected  Trouser , got T-shirt/top :  8 out of 1016 i.e. 0.79 %\n",
      "Expected  Trouser , got Trouser :  969 out of 1016 i.e. 95.37 %\n",
      "\n",
      "------------------Sobre 5%-------------------\n",
      "Expected  Ankle boot , got Ankle boot :  907 out of 960 i.e. 94.48 %\n",
      "Expected  Bag , got Bag :  949 out of 1017 i.e. 93.31 %\n",
      "Expected  Coat , got Coat :  814 out of 1028 i.e. 79.18 %\n",
      "Expected  Coat , got Pullover :  87 out of 1028 i.e. 8.46 %\n",
      "Expected  Coat , got Shirt :  81 out of 1028 i.e. 7.88 %\n",
      "Expected  Dress , got Dress :  869 out of 1001 i.e. 86.81 %\n",
      "Expected  Pullover , got Coat :  135 out of 1005 i.e. 13.43 %\n",
      "Expected  Pullover , got Pullover :  749 out of 1005 i.e. 74.53 %\n",
      "Expected  Pullover , got Shirt :  89 out of 1005 i.e. 8.86 %\n",
      "Expected  Sandal , got Sandal :  916 out of 985 i.e. 92.99 %\n",
      "Expected  Shirt , got Coat :  103 out of 990 i.e. 10.4 %\n",
      "Expected  Shirt , got Pullover :  119 out of 990 i.e. 12.02 %\n",
      "Expected  Shirt , got Shirt :  570 out of 990 i.e. 57.58 %\n",
      "Expected  Shirt , got T-shirt/top :  157 out of 990 i.e. 15.86 %\n",
      "Expected  Sneaker , got Sneaker :  930 out of 994 i.e. 93.56 %\n",
      "Expected  T-shirt/top , got Shirt :  87 out of 1004 i.e. 8.67 %\n",
      "Expected  T-shirt/top , got T-shirt/top :  830 out of 1004 i.e. 82.67 %\n",
      "Expected  Trouser , got Trouser :  969 out of 1016 i.e. 95.37 %\n"
     ]
    }
   ],
   "source": [
    "assignation_freq_cv, totals_cv = freq_and_totals(new_a_validate,validate_y)\n",
    "for k,v in OrderedDict(sorted(assignation_freq_cv.items())):\n",
    "    print(\"Expected \",k,\", got\", v, \": \", assignation_freq_cv[k,v], \"out of\", totals_cv[k][0], \"i.e.\", round(assignation_freq_cv[k,v]*100/totals_cv[k][0],2),\"%\")\n",
    "print(\"\\n------------------Sobre 5%-------------------\")\n",
    "for k,v in OrderedDict(sorted(assignation_freq_cv.items())):\n",
    "    if(round(assignation_freq_cv[k,v]*100/totals_cv[k][0],2)>=5):\n",
    "        print(\"Expected \",k,\", got\", v, \": \", assignation_freq_cv[k,v], \"out of\", totals_cv[k][0], \"i.e.\", round(assignation_freq_cv[k,v]*100/totals_cv[k][0],2),\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> NOTA: </b> \n",
    "    <ul> \n",
    "        <li> Se mantiene que \"Shirt\", \"Pullover\" y \"Coat\" son los primers tres más bajos, respectivamente. Sin embargo, puede notarse que los porcentajes erróneos, especialmente clasificar errónamente una \"Shirt\" como un \"Coat\", han aumentado. Sin embargo, para \"Coat,\" esta diferencia es menor.\n",
    "        <li> Nuevamente, ninguno de los elementos tuvo un accuracy del 100%, pero esta vez el más alto fue el de \"Trouser,\" cuyo porcentaje de accuracy es bastante parecido al del training set. \"Sandal\" disminuyó significativamente, y hay casos en los que se clasificó erróneamente como \"Bag\" y \"Dress,\" al igual que aumentó el porcentaje de veces que se clasificó como \"Ankle boot\" o \"Sneaker.\"\n",
    "        <li> Si bien \"Bag\" disminuyó en accuracy, se puede ver que mientras en el training set se clasificó al menos una vez en cada uno de los labels erróneos, en el cross validation set no se ha clasificado en ninguna instanca como \"Ankle boot\".\n",
    "    </ul>\n",
    "\n",
    "Si bien el accuracy en general tanto para el training y el cross validation sets, debido a estas observaciones, vale la pena preguntarse si un modelo con más neuronas aumentaría el accuracy. Según las observaciones, podría ser seguro asumir que hasta el momento no se presenta overfitting, si no tal vez algún tipo de bias, ya que todas las categorias presentan incluso en el training set al menos 3 categorizaciones erróneas, algunas incluso que no parecen hacer sentido (como todo lo que se clasifica erróneamente como \"Bag\", o vestimentas que se confundieron con alguno de los tipos de zapato)\n",
    "\n",
    "## 1.2 Modelo #2\n",
    "Este, nuevamente por problemas de cache de jupyter con respecto a scipy, puede encontrarse en el archivo jupyter2.py. Esta tenía poco menos de 1.5x la cantidad de neuronas en la capa escondida de la anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133\n"
     ]
    }
   ],
   "source": [
    "new_thetas_2 = np.load('result_model_2.npy')\n",
    "NETWORK_ARCH_2 = np.array([\n",
    "    784,\n",
    "    round((3/2)*(784*10)**0.5), # Miremos que pasa si aumentamos la cantidad de neuronas\n",
    "    10\n",
    "])\n",
    "theta_shapes_2 = np.hstack((\n",
    "    NETWORK_ARCH_2[1:].reshape(len(NETWORK_ARCH_2)-1,1),\n",
    "    (NETWORK_ARCH_2[:-1]+1).reshape(len(NETWORK_ARCH_2)-1,1)\n",
    "))\n",
    "print(NETWORK_ARCH_2[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success:  50000  out of  50000 , i.e.  100.0\n",
      "Success:  8714  out of  10000 , i.e.  87.14\n"
     ]
    }
   ],
   "source": [
    "train_model_2 = nn.feed_forward(nn.inflate_matrices(new_thetas_2, theta_shapes_2), train_X)\n",
    "validate_model_2 = nn.feed_forward(nn.inflate_matrices(new_thetas_2, theta_shapes_2), validate_X)\n",
    "\n",
    "accuracy(train_model_2,train_y)\n",
    "accuracy(validate_model_2,validate_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado que se obtuvo un resultado para train del 100%, pero de 87% para el cross validation set, descartamos este modelo, ya que parece ser un caso de overfitting.\n",
    "\n",
    "# 2. Test Set\n",
    "Utilizando el primer modelo que teníamos, evaluemos el resultado con el test set (no vale la pena evaluar el segundo modelo, ya que, como se mencionó anteriormente, al obtener un 100% de accuracy para el training set, se sospecha que este está overfitteado):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************Modelo 1: 1 hidden layer de 90 neuronas****************\n",
      "Success:  8498  out of  10000 , i.e.  84.98\n",
      "\n",
      "!!!!!!!!!!!!!!!FREQUENCIES!!!!!!!!!!!!!!!\n",
      "Expected  Ankle boot , got Ankle boot :  936 out of 1000 i.e. 93.6 %\n",
      "Expected  Ankle boot , got Bag :  1 out of 1000 i.e. 0.1 %\n",
      "Expected  Ankle boot , got Sandal :  24 out of 1000 i.e. 2.4 %\n",
      "Expected  Ankle boot , got Sneaker :  39 out of 1000 i.e. 3.9 %\n",
      "Expected  Bag , got Ankle boot :  1 out of 1000 i.e. 0.1 %\n",
      "Expected  Bag , got Bag :  942 out of 1000 i.e. 94.2 %\n",
      "Expected  Bag , got Coat :  7 out of 1000 i.e. 0.7 %\n",
      "Expected  Bag , got Dress :  5 out of 1000 i.e. 0.5 %\n",
      "Expected  Bag , got Pullover :  7 out of 1000 i.e. 0.7 %\n",
      "Expected  Bag , got Sandal :  7 out of 1000 i.e. 0.7 %\n",
      "Expected  Bag , got Shirt :  19 out of 1000 i.e. 1.9 %\n",
      "Expected  Bag , got Sneaker :  3 out of 1000 i.e. 0.3 %\n",
      "Expected  Bag , got T-shirt/top :  8 out of 1000 i.e. 0.8 %\n",
      "Expected  Bag , got Trouser :  1 out of 1000 i.e. 0.1 %\n",
      "Expected  Coat , got Bag :  6 out of 1000 i.e. 0.6 %\n",
      "Expected  Coat , got Coat :  791 out of 1000 i.e. 79.1 %\n",
      "Expected  Coat , got Dress :  25 out of 1000 i.e. 2.5 %\n",
      "Expected  Coat , got Pullover :  89 out of 1000 i.e. 8.9 %\n",
      "Expected  Coat , got Sandal :  1 out of 1000 i.e. 0.1 %\n",
      "Expected  Coat , got Shirt :  78 out of 1000 i.e. 7.8 %\n",
      "Expected  Coat , got T-shirt/top :  5 out of 1000 i.e. 0.5 %\n",
      "Expected  Coat , got Trouser :  5 out of 1000 i.e. 0.5 %\n",
      "Expected  Dress , got Bag :  4 out of 1000 i.e. 0.4 %\n",
      "Expected  Dress , got Coat :  33 out of 1000 i.e. 3.3 %\n",
      "Expected  Dress , got Dress :  851 out of 1000 i.e. 85.1 %\n",
      "Expected  Dress , got Pullover :  21 out of 1000 i.e. 2.1 %\n",
      "Expected  Dress , got Shirt :  27 out of 1000 i.e. 2.7 %\n",
      "Expected  Dress , got T-shirt/top :  43 out of 1000 i.e. 4.3 %\n",
      "Expected  Dress , got Trouser :  21 out of 1000 i.e. 2.1 %\n",
      "Expected  Pullover , got Bag :  5 out of 1000 i.e. 0.5 %\n",
      "Expected  Pullover , got Coat :  111 out of 1000 i.e. 11.1 %\n",
      "Expected  Pullover , got Dress :  8 out of 1000 i.e. 0.8 %\n",
      "Expected  Pullover , got Pullover :  767 out of 1000 i.e. 76.7 %\n",
      "Expected  Pullover , got Shirt :  91 out of 1000 i.e. 9.1 %\n",
      "Expected  Pullover , got T-shirt/top :  16 out of 1000 i.e. 1.6 %\n",
      "Expected  Pullover , got Trouser :  2 out of 1000 i.e. 0.2 %\n",
      "Expected  Sandal , got Ankle boot :  35 out of 1000 i.e. 3.5 %\n",
      "Expected  Sandal , got Bag :  2 out of 1000 i.e. 0.2 %\n",
      "Expected  Sandal , got Dress :  1 out of 1000 i.e. 0.1 %\n",
      "Expected  Sandal , got Pullover :  1 out of 1000 i.e. 0.1 %\n",
      "Expected  Sandal , got Sandal :  916 out of 1000 i.e. 91.6 %\n",
      "Expected  Sandal , got Sneaker :  45 out of 1000 i.e. 4.5 %\n",
      "Expected  Shirt , got Bag :  14 out of 1000 i.e. 1.4 %\n",
      "Expected  Shirt , got Coat :  87 out of 1000 i.e. 8.7 %\n",
      "Expected  Shirt , got Dress :  38 out of 1000 i.e. 3.8 %\n",
      "Expected  Shirt , got Pullover :  105 out of 1000 i.e. 10.5 %\n",
      "Expected  Shirt , got Shirt :  598 out of 1000 i.e. 59.8 %\n",
      "Expected  Shirt , got T-shirt/top :  155 out of 1000 i.e. 15.5 %\n",
      "Expected  Shirt , got Trouser :  3 out of 1000 i.e. 0.3 %\n",
      "Expected  Sneaker , got Ankle boot :  57 out of 1000 i.e. 5.7 %\n",
      "Expected  Sneaker , got Bag :  2 out of 1000 i.e. 0.2 %\n",
      "Expected  Sneaker , got Sandal :  31 out of 1000 i.e. 3.1 %\n",
      "Expected  Sneaker , got Sneaker :  910 out of 1000 i.e. 91.0 %\n",
      "Expected  T-shirt/top , got Bag :  13 out of 1000 i.e. 1.3 %\n",
      "Expected  T-shirt/top , got Coat :  4 out of 1000 i.e. 0.4 %\n",
      "Expected  T-shirt/top , got Dress :  42 out of 1000 i.e. 4.2 %\n",
      "Expected  T-shirt/top , got Pullover :  23 out of 1000 i.e. 2.3 %\n",
      "Expected  T-shirt/top , got Sandal :  3 out of 1000 i.e. 0.3 %\n",
      "Expected  T-shirt/top , got Shirt :  98 out of 1000 i.e. 9.8 %\n",
      "Expected  T-shirt/top , got T-shirt/top :  814 out of 1000 i.e. 81.4 %\n",
      "Expected  T-shirt/top , got Trouser :  3 out of 1000 i.e. 0.3 %\n",
      "Expected  Trouser , got Coat :  6 out of 1000 i.e. 0.6 %\n",
      "Expected  Trouser , got Dress :  12 out of 1000 i.e. 1.2 %\n",
      "Expected  Trouser , got Pullover :  3 out of 1000 i.e. 0.3 %\n",
      "Expected  Trouser , got Sandal :  1 out of 1000 i.e. 0.1 %\n",
      "Expected  Trouser , got Shirt :  3 out of 1000 i.e. 0.3 %\n",
      "Expected  Trouser , got T-shirt/top :  2 out of 1000 i.e. 0.2 %\n",
      "Expected  Trouser , got Trouser :  973 out of 1000 i.e. 97.3 %\n",
      "\n",
      "------------------Sobre 5%-------------------\n",
      "Expected  Ankle boot , got Ankle boot :  936 out of 1000 i.e. 93.6 %\n",
      "Expected  Bag , got Bag :  942 out of 1000 i.e. 94.2 %\n",
      "Expected  Coat , got Coat :  791 out of 1000 i.e. 79.1 %\n",
      "Expected  Coat , got Pullover :  89 out of 1000 i.e. 8.9 %\n",
      "Expected  Coat , got Shirt :  78 out of 1000 i.e. 7.8 %\n",
      "Expected  Dress , got Dress :  851 out of 1000 i.e. 85.1 %\n",
      "Expected  Pullover , got Coat :  111 out of 1000 i.e. 11.1 %\n",
      "Expected  Pullover , got Pullover :  767 out of 1000 i.e. 76.7 %\n",
      "Expected  Pullover , got Shirt :  91 out of 1000 i.e. 9.1 %\n",
      "Expected  Sandal , got Sandal :  916 out of 1000 i.e. 91.6 %\n",
      "Expected  Shirt , got Coat :  87 out of 1000 i.e. 8.7 %\n",
      "Expected  Shirt , got Pullover :  105 out of 1000 i.e. 10.5 %\n",
      "Expected  Shirt , got Shirt :  598 out of 1000 i.e. 59.8 %\n",
      "Expected  Shirt , got T-shirt/top :  155 out of 1000 i.e. 15.5 %\n",
      "Expected  Sneaker , got Ankle boot :  57 out of 1000 i.e. 5.7 %\n",
      "Expected  Sneaker , got Sneaker :  910 out of 1000 i.e. 91.0 %\n",
      "Expected  T-shirt/top , got Shirt :  98 out of 1000 i.e. 9.8 %\n",
      "Expected  T-shirt/top , got T-shirt/top :  814 out of 1000 i.e. 81.4 %\n",
      "Expected  Trouser , got Trouser :  973 out of 1000 i.e. 97.3 %\n"
     ]
    }
   ],
   "source": [
    "a_test_1 = nn.feed_forward(new_thetas, test_X)\n",
    "print('****************Modelo 1: 1 hidden layer de 90 neuronas****************')\n",
    "accuracy(a_test_1,test_y)\n",
    "\n",
    "print('\\n!!!!!!!!!!!!!!!FREQUENCIES!!!!!!!!!!!!!!!')\n",
    "assignation_freq_t1, totals_t1 = freq_and_totals(a_test_1,test_y)\n",
    "for k,v in OrderedDict(sorted(assignation_freq_t1.items())):\n",
    "    print(\"Expected \",k,\", got\", v, \": \", assignation_freq_t1[k,v], \"out of\", totals_t1[k][0], \"i.e.\", round(assignation_freq_t1[k,v]*100/totals_t1[k][0],2),\"%\")\n",
    "print(\"\\n------------------Sobre 5%-------------------\")\n",
    "for k,v in OrderedDict(sorted(assignation_freq_t1.items())):\n",
    "    if(round(assignation_freq_t1[k,v]*100/totals_t1[k][0],2)>=5):\n",
    "        print(\"Expected \",k,\", got\", v, \": \", assignation_freq_t1[k,v], \"out of\", totals_t1[k][0], \"i.e.\", round(assignation_freq_t1[k,v]*100/totals_t1[k][0],2),\"%\")\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Conclusiones y recomendaciones\n",
    "Dado que para el primer modelo se obtienen accuracies sobre el 80%, y estas son bastante cercanas entre sí, este es un modelo válido. También se puede observar que los errores de clasificación son consistentes en los tres datasets, tendiendo a confundir especialmente \"Shirts\" con otros artículos, confundir \"Pullover,\" \"Coat\" y \"Shirt\" entre sí, y teniendo mayor facilidad para identificar \"Trouser,\" \"Sandal\" y \"Bag\". Por lo tanto, se considera que este es un buen modelo.\n",
    "\n",
    "Se notó que, al aumentar en casi 1.5x la cantidad de neuronas, el modelo quedaba bastante overfitteado. Sin embargo, para este modelo también se inicializaron thetas más pequeños (de lo contrario, la función de minimize se detenía por la iteración 16), así que esto pudo haber influenciado ligeramente. Se recomienda, por lo tanto, utilizar el mismo rango y ajustes para generar los thetas iniciales al azar.\n",
    "\n",
    "También, según los dos modelos realizados, se considerea apropiado realizar un modelo que tenga entre 90 y 133 neuronas, ya que si bien los resultados son bastante buenos, podrían mejorarse, siempre evitando caer en casos de overfitting. Esto podría ayudar a refinar las clasificaciones de las categorías que consistentemente fueron las más bajas, especialmente \"Shirt,\" al igual que reducir en general las clasificaciones erróneas, ya que cada artículo se clasificó erróneamente como mínimo con otros 3 artículos.\n",
    "\n",
    "A pesar de que no era requisito de implementación para el laboratorio, se recomienda también evaluar el modelo con regularización, ya que esto sería más certero y fácil de identificar los cambios necesarios al modelo, a diferencia de ir variando el número de neuronas en la capa oculta a puro tanteo (también, dado el tiempo de espera de cada corrida de un nuevo modelo, este último puede tornarse en algo muy largo)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
